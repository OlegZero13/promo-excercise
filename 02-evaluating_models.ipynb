{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c93bf7-d85c-47a7-ad7a-fa3a9256567a",
   "metadata": {},
   "source": [
    "# 2. Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0620da-c324-40db-b932-1f0ee6777445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "X_raw = pd.read_pickle(\"data/X_raw.pkl\")\n",
    "y_raw = pd.read_pickle(\"data/y_raw.pkl\")\n",
    "\n",
    "\n",
    "NUMERIC_FEATURES = [\"CreditScore\", \"Age\", \"Balance\", \"Tenure\", \"EstimatedSalary\"]\n",
    "CATEGORICAL_FEATURES = [\"Geography\", \"Gender\", \"NumOfProducts\", \"HasCrCard\", \"IsActiveMember\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb068c1-5153-4dcb-b4fa-d17ae45ca34e",
   "metadata": {},
   "source": [
    "## Converting and generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af5cd3f-7e03-4199-a070-a457390560ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15634602</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15647311</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619304</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701354</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15737888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NumOfProducts  HasCrCard  IsActiveMember  Geography_France  \\\n",
       "CustomerId                                                               \n",
       "15634602              1.0        1.0             1.0               1.0   \n",
       "15647311              1.0        0.0             1.0               0.0   \n",
       "15619304              3.0        1.0             0.0               1.0   \n",
       "15701354              2.0        0.0             0.0               1.0   \n",
       "15737888              1.0        1.0             1.0               0.0   \n",
       "\n",
       "            Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \\\n",
       "CustomerId                                                                   \n",
       "15634602                  0.0              0.0            1.0          0.0   \n",
       "15647311                  0.0              1.0            1.0          0.0   \n",
       "15619304                  0.0              0.0            1.0          0.0   \n",
       "15701354                  0.0              0.0            1.0          0.0   \n",
       "15737888                  0.0              1.0            1.0          0.0   \n",
       "\n",
       "            CreditScore   Age    Balance  Tenure  EstimatedSalary  \n",
       "CustomerId                                                         \n",
       "15634602          619.0  42.0       0.00     2.0        101348.88  \n",
       "15647311          608.0  41.0   83807.86     1.0        112542.58  \n",
       "15619304          502.0  42.0  159660.80     8.0        113931.57  \n",
       "15701354          699.0  39.0       0.00     1.0         93826.63  \n",
       "15737888          850.0  43.0  125510.82     2.0         79084.10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(X_raw):\n",
    "    return pd.concat([\n",
    "            pd.get_dummies(X_raw[CATEGORICAL_FEATURES]).astype(float),\n",
    "            X_raw[NUMERIC_FEATURES].astype(float),\n",
    "        ], axis=1)\n",
    "\n",
    "X = get_features(X_raw)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d24794-50da-44d1-947c-a126e8ce1b21",
   "metadata": {},
   "source": [
    "## Train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15b56ae-3920-4b45-8702-dbf5eb7e6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: (8000, 13), labels: (8000,),\n",
      "Test set:     (2000, 13), labels: (2000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_raw[\"Exited\"].to_numpy().flatten(), train_size=8000, random_state=42)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training set: {X_train.shape}, labels: {y_train.shape},\n",
    "Test set:     {X_test.shape}, labels: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2330c398-a1ff-47e2-a5ca-5ffbe353ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(y_train.sum() / y_train.shape[0], y_test.sum() / y_test.shape[0], rtol=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8cc4b-da23-49ba-b142-eda45d28f62e",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8336d95f-0d58-4628-a632-a0fdfcf1eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_logistic_regression = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(penalty=\"none\")\n",
    ")\n",
    "\n",
    "pipe_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_LR = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_LR[\"y_train_pred\"] = pipe_logistic_regression.predict(X_train)\n",
    "outputs_LR[\"y_test_pred\"] = pipe_logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6fd540-f893-46be-8e32-ba27835bc27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "============================================================\n",
      "Training:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.8268    0.9644    0.8903      6356\n",
      "     churned     0.6143    0.2190    0.3229      1644\n",
      "\n",
      "    accuracy                         0.8113      8000\n",
      "   macro avg     0.7206    0.5917    0.6066      8000\n",
      "weighted avg     0.7831    0.8113    0.7737      8000\n",
      "\n",
      "Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.8309    0.9602    0.8909      1607\n",
      "     churned     0.5524    0.2010    0.2948       393\n",
      "\n",
      "    accuracy                         0.8110      2000\n",
      "   macro avg     0.6917    0.5806    0.5928      2000\n",
      "weighted avg     0.7762    0.8110    0.7737      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def full_report(outputs, pipe):\n",
    "    target_names = [\"stayed\", \"churned\"]\n",
    "    print(f\"Model: {pipe[-1].__class__.__name__}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training:\\n\", classification_report(outputs[\"y_train\"], outputs[\"y_train_pred\"], target_names=target_names, digits=4))\n",
    "    print(\"Test:\\n\", classification_report(outputs[\"y_test\"], outputs[\"y_test_pred\"], target_names=target_names, digits=4))\n",
    "    \n",
    "full_report(outputs_LR, pipe_logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a2bd0-7864-44e6-af8d-454b563ceaf1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a803cf-a469-43f0-8f6f-181bf58c19db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier\n",
      "============================================================\n",
      "Training:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     1.0000    1.0000    1.0000      6356\n",
      "     churned     1.0000    1.0000    1.0000      1644\n",
      "\n",
      "    accuracy                         1.0000      8000\n",
      "   macro avg     1.0000    1.0000    1.0000      8000\n",
      "weighted avg     1.0000    1.0000    1.0000      8000\n",
      "\n",
      "Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.8753    0.8475    0.8612      1607\n",
      "     churned     0.4482    0.5064    0.4755       393\n",
      "\n",
      "    accuracy                         0.7805      2000\n",
      "   macro avg     0.6618    0.6770    0.6684      2000\n",
      "weighted avg     0.7914    0.7805    0.7854      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_decision_tree = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "pipe_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_DT = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_DT[\"y_train_pred\"] = pipe_decision_tree.predict(X_train)\n",
    "outputs_DT[\"y_test_pred\"] = pipe_decision_tree.predict(X_test)\n",
    "\n",
    "full_report(outputs_DT, pipe_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf5e05-72a4-43f9-9af9-8ef4258a4870",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1814a422-2002-4d86-827b-c4cfff2cc912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "============================================================\n",
      "Training:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.9998    1.0000    0.9999      6356\n",
      "     churned     1.0000    0.9994    0.9997      1644\n",
      "\n",
      "    accuracy                         0.9999      8000\n",
      "   macro avg     0.9999    0.9997    0.9998      8000\n",
      "weighted avg     0.9999    0.9999    0.9999      8000\n",
      "\n",
      "Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.8826    0.9633    0.9212      1607\n",
      "     churned     0.7602    0.4758    0.5853       393\n",
      "\n",
      "    accuracy                         0.8675      2000\n",
      "   macro avg     0.8214    0.7196    0.7532      2000\n",
      "weighted avg     0.8585    0.8675    0.8552      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_random_forest = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "pipe_random_forest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_RF = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_RF[\"y_train_pred\"] = pipe_random_forest.predict(X_train)\n",
    "outputs_RF[\"y_test_pred\"] = pipe_random_forest.predict(X_test)\n",
    "\n",
    "full_report(outputs_RF, pipe_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e725c-255c-45f7-b450-49d908e40ba7",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32b0765-e019-49a6-afa9-031ac8881258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/Projects/promo-excercise/env/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier\n",
      "============================================================\n",
      "Training:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.9533    0.9931    0.9728      6356\n",
      "     churned     0.9681    0.8120    0.8832      1644\n",
      "\n",
      "    accuracy                         0.9559      8000\n",
      "   macro avg     0.9607    0.9026    0.9280      8000\n",
      "weighted avg     0.9564    0.9559    0.9544      8000\n",
      "\n",
      "Test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      stayed     0.8870    0.9477    0.9164      1607\n",
      "     churned     0.7032    0.5064    0.5888       393\n",
      "\n",
      "    accuracy                         0.8610      2000\n",
      "   macro avg     0.7951    0.7270    0.7526      2000\n",
      "weighted avg     0.8509    0.8610    0.8520      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe_xgb = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_XGB = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_XGB[\"y_train_pred\"] = pipe_xgb.predict(X_train)\n",
    "outputs_XGB[\"y_test_pred\"] = pipe_xgb.predict(X_test)\n",
    "\n",
    "full_report(outputs_XGB, pipe_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39df2f-0b5f-43aa-aa46-7d38970db47b",
   "metadata": {},
   "source": [
    "## Summary(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28397c0b-6954-44c7-865c-ccd217d58bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "outputs = [\n",
    "    outputs_LR, outputs_DT, outputs_RF, outputs_XGB\n",
    "]\n",
    "\n",
    "pipes = [\n",
    "    pipe_logistic_regression,\n",
    "    pipe_decision_tree,\n",
    "    pipe_random_forest,\n",
    "    pipe_xgb,\n",
    "]\n",
    "\n",
    "models_cols = [p[-1].__class__.__name__ for p in pipes]\n",
    "\n",
    "\n",
    "def metrics_report(outputs, metrics_fn):\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame([\n",
    "            metrics_fn(o[\"y_train\"], o[f\"y_train_pred\"]) for o in outputs\n",
    "        ], columns=[\"train\"], index=models_cols).T,\n",
    "        pd.DataFrame([\n",
    "            metrics_fn(o[\"y_test\"], o[f\"y_test_pred\"]) for o in outputs\n",
    "        ], columns=[\"test\"], index=models_cols).T,\n",
    "    ], axis=0).T\n",
    "    df.name = metrics_fn.__name__\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e90afb5-538d-4715-b052-ebd7cb18bfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.218978</td>\n",
       "      <td>0.201018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train      test\n",
       "LogisticRegression      0.218978  0.201018\n",
       "DecisionTreeClassifier  1.000000  0.506361\n",
       "RandomForestClassifier  0.999392  0.475827\n",
       "XGBClassifier           0.812044  0.506361"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_report(outputs, recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20deed63-a9bc-49dd-8090-688faf3a2bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.614334</td>\n",
       "      <td>0.552448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.968093</td>\n",
       "      <td>0.703180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train      test\n",
       "LogisticRegression      0.614334  0.552448\n",
       "DecisionTreeClassifier  1.000000  0.448198\n",
       "RandomForestClassifier  1.000000  0.760163\n",
       "XGBClassifier           0.968093  0.703180"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_report(outputs, precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21277ea7-2bd3-43ca-af27-f52916bd1c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.322870</td>\n",
       "      <td>0.294776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.585290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.883229</td>\n",
       "      <td>0.588757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train      test\n",
       "LogisticRegression      0.322870  0.294776\n",
       "DecisionTreeClassifier  1.000000  0.475508\n",
       "RandomForestClassifier  0.999696  0.585290\n",
       "XGBClassifier           0.883229  0.588757"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_report(outputs, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2984be4-2de4-4df2-b436-c0c0ffbec0a8",
   "metadata": {},
   "source": [
    "## Experiment - Reducing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38bdd1c-329f-43ea-ad85-a28ec5a739f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: (8000, 8), labels: (8000,),\n",
      "Test set:     (2000, 8), labels: (2000,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/Projects/promo-excercise/env/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.218978</td>\n",
       "      <td>0.201018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.500608</td>\n",
       "      <td>0.475827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train      test\n",
       "LogisticRegression      0.218978  0.201018\n",
       "DecisionTreeClassifier  1.000000  0.506361\n",
       "RandomForestClassifier  0.999392  0.475827\n",
       "XGBClassifier           0.812044  0.506361\n",
       "XGBClassifier           0.500608  0.475827"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEMOGRAPHIC_FEATURES = [c for c in X.columns if c.startswith(\"Geography\") or c.startswith(\"Gender\")] + [\"Age\"]\n",
    "\n",
    "X_v1 = X[DEMOGRAPHIC_FEATURES + [\"IsActiveMember\", \"NumOfProducts\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_v1, y_raw[\"Exited\"].to_numpy().flatten(), train_size=8000, random_state=42)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training set: {X_train.shape}, labels: {y_train.shape},\n",
    "Test set:     {X_test.shape}, labels: {y_test.shape}\n",
    "\"\"\")\n",
    "\n",
    "pipe_xgb_v1 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "pipe_xgb_v1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_XGB_v1 = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_XGB_v1[\"y_train_pred\"] = pipe_xgb_v1.predict(X_train)\n",
    "outputs_XGB_v1[\"y_test_pred\"] = pipe_xgb_v1.predict(X_test)\n",
    "\n",
    "outputs.append(outputs_XGB_v1)\n",
    "pipes.append(pipe_xgb_v1)\n",
    "models_cols = [p[-1].__class__.__name__ for p in pipes]\n",
    "\n",
    "metrics_report(outputs, recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb0aed-5167-4550-88b2-a9f6164b4205",
   "metadata": {},
   "source": [
    "No... the other features still seem to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14f7f3-018e-41aa-9f08-5f5a89fac320",
   "metadata": {},
   "source": [
    "### Experiment 2 - adding regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cabf5f1-4b00-48a3-88aa-0aa7954d4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: (8000, 13), labels: (8000,),\n",
      "Test set:     (2000, 13), labels: (2000,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/Projects/promo-excercise/env/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.218978</td>\n",
       "      <td>0.201018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.500608</td>\n",
       "      <td>0.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.864964</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           train      test\n",
       "LogisticRegression      0.218978  0.201018\n",
       "DecisionTreeClassifier  1.000000  0.506361\n",
       "RandomForestClassifier  0.999392  0.475827\n",
       "XGBClassifier           0.812044  0.506361\n",
       "XGBClassifier           0.500608  0.475827\n",
       "XGBClassifier           0.864964  0.503817"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_raw[\"Exited\"].to_numpy().flatten(), train_size=8000, random_state=42)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training set: {X_train.shape}, labels: {y_train.shape},\n",
    "Test set:     {X_test.shape}, labels: {y_test.shape}\n",
    "\"\"\")\n",
    "\n",
    "pipe_xgb_v2 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBClassifier(reg_lambda=0.001)\n",
    ")\n",
    "\n",
    "pipe_xgb_v2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "outputs_XGB_v2 = {\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "}\n",
    "outputs_XGB_v2[\"y_train_pred\"] = pipe_xgb_v2.predict(X_train)\n",
    "outputs_XGB_v2[\"y_test_pred\"] = pipe_xgb_v2.predict(X_test)\n",
    "\n",
    "outputs.append(outputs_XGB_v2)\n",
    "pipes.append(pipe_xgb_v2)\n",
    "models_cols = [p[-1].__class__.__name__ for p in pipes]\n",
    "\n",
    "metrics_report(outputs, recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a5fb4-b0c4-4fc5-ba65-5ab723eb2509",
   "metadata": {},
   "source": [
    "Not really either... Tried with both L1 and L2 regularizaiton, but it fails to increase the test set recall.\n",
    "It only increases the training set recall or other metrics.\n",
    "\n",
    "I am so focused on recall because, I believe this metrics has the most business value.\n",
    "While a model may be better in terms of f1 score or precision (not to mention the accuracy, which is a bad metrics here anyway),\n",
    "recall will allow us to pick the customers we believe may be about to churn.\n",
    "Therefore, it shoudl cost the company less to offer some benefits to prospective non-churners (focusing on precision)\n",
    "rather than not to detect a genuine churner.\n",
    "Since recall (sensitivity) is the ratio of the true positives to a sum of true positives and false negatives,\n",
    "this is the metrics that focuses on _detection_ of the prospective churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8c850-2d35-4770-a8a6-4cbc98de52ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
